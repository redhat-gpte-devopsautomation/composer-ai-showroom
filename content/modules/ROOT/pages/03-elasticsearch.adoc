= Deploying Vector Database with Elasticsearch

In our deployment we will be utilizing Elasticsearch for our vector database.

Elasticsearch is a Red Hat partner and Red Hat has announced future integrations within OpenShift AI.

== Creating the Elasticsearch Instance

The Elasticsearch (ECK) Operator has already been installed on the cluster for you.

To install elasticsearch into your cluster, click the `+` in the top right hand corner and paste the following objects in and click Create.

```
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch
  namespace: elastic-vectordb
  labels:
    app: "elasticsearch"
spec:
  http:
    tls:
      selfSignedCertificate:
        disabled: true
  nodeSets:
    - config:
        node.roles:
          - master
          - data
        node.attr.attr_name: attr_value
        node.store.allow_mmap: false
      podTemplate:
        metadata:
          labels:
            foo: bar
        spec:
          containers:
            - name: elasticsearch
              resources:
                limits:
                  cpu: 2
                  memory: 4Gi
                requests:
                  cpu: 1
                  memory: 4Gi
      name: default
      count: 3
  version: 8.16.0
```



// == Deploying Elasticsearch Instance

// # Instructions for deploying Elasticsearch instance

This will install both the elasticsearch eck operator and the Elasticsearch Custom resource.  

== Populating Vector Database

Now that we have the elasticsearch cluster up and running, we must ingest documents into it.  This will allow us to create Retrieval Augmented Generation (RAG) based assistants that Composer AI can use.

[NOTE]
====
For demonstration purposes we will be ingesting documentation for various Red Hat products.  However, it is import to keep in mind that basically any data source can be used in the context of RAG, including the live web.  If you have ever used the chatbot Perplexity AI, that is what it is doing behind the scenes. 

====

# Instructions for executing the ingestion pipeline

To get you started, we have included an ingestion pipeline to populate the elasticsearch instance with information pulled from openshift documentation.  Go to pipelines in the composer-ai-apps namespaces.  Run the `ingestion-pipeline` pipeline with the default parameters.  Set the `source` workspace to the VolumeClaimTemplate option.  

image::03-show-pipeline-1.png[Instantiate Template]

image::03-show-pipeline-2.png[Instantiate Template]

The progress can be viewed in the "Experiments and runs" section in the Openshift AI console.

image::03-view-experiments.png[Instantiate Template]

From here you can view the progress of the Kubeflow Pipeline (KFP), as well as the logs of individual steps, similar to Tekton.  



