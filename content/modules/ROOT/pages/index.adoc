= Composer AI and building Productivity Apps

== What is Composer AI?

Composer AI is a service lead engagement designed to accelerate the adoption of generative AI.

It's a full-stack AI deployment for OpenShift that includes all the necessary components for a Generative AI solution, including required operators, datasources, LLMs, and a custom application for querying the LLM.

== Architecture

image::composer_ai_arch.drawio.png[Composer AI Architecture]

The above is a high-level architecture diagram of what's included in Composer AI. The major components are:

- https://github.com/redhat-composer-ai/cluster-gitops[Cluster GitOps Repository]-  Contains all the required OpenShift components for Composer.
- https://github.com/redhat-composer-ai/appOfApps[App of Apps Repository]- Installs the Composer AI-specific components.
  * https://github.com/redhat-composer-ai/appOfApps/tree/main/chatbot-ui[Chatbot UI]- Patterfly User Interface for building and interacting with assistants
  * https://github.com/redhat-composer-ai/appOfApps/tree/main/conductor[Conductor]- Quarkus API that utilizes https://docs.langchain4j.dev/intro[LangChain4J] and the https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html[Quarkus Overlay] for AI functionality.
  * https://github.com/redhat-composer-ai/appOfApps/tree/main/data-ingestion[Data Ingestion]- KFP Pipeline that is automatically kicked off and can be used as an example for ingesting data.
  * https://github.com/redhat-composer-ai/appOfApps/tree/main/vllm[LLM]- vLLM serving runtime utilizing a https://github.com/redhat-ai-services/modelcar-catalog[Model Car] containing a Granite Model.

== Today's Lab

As mentioned above, when installed using the default GitOps approach or retrieved through the https://catalog.demo.redhat.com/catalog?item=babylon-catalog-prod/sandboxes-gpte.ocp4-composer-ai.prod&utm_source=webapp&utm_medium=share-link[demo.redhat.com catalog], your cluster will come with an instance of vLLM/Granite and an Elasticsearch Vector Database preinstalled.

However, for this lab, we will only be including the Conductor API and the Composer AI on the provisioned cluster. This allows you to install your own instance of vLLM using Red Hat OpenShift AI and an Elasticsearch Database. You will also create new assistants using Composer AI and ingest and use data from our Red Hat documentation to more mimic match what you may be doing in a customer environment.

== Important Links

Here are some important links to help you on your journey:

* https://console-openshift-console.{openshift_cluster_ingress_domain}[OpenShift Web Console] 
* https://rhods-dashboard-redhat-ods-applications.{openshift_cluster_ingress_domain}[OpenShift AI Dashboard]
* https://openshift-gitops-server-openshift-gitops.{openshift_cluster_ingress_domain}[Cluster Scoped ArgoCD]
* https://argocd-server-composer-ai-gitops.{openshift_cluster_ingress_domain}[Composer AI ArgoCD]
* http://https://chatbot-ui-composer-ai-apps.{openshift_cluster_ingress_domain}[Composer AI UI]


== Important Credentials

The cluster admin user can be used to access all of the resources on the cluster including the ArgoCD instance and OpenShift AI Dashboard.

Cluster admin user: `{openshift_cluster_admin_username}`

Cluster admin password: `{openshift_cluster_admin_password}`
